---
# tasks file for roles/apigee-hybrid-gke-create
- name: Set gke cache
  set_fact:
    cacheable: yes
    ATTACHED_CLUSTER: False
    NODE_COUNT: "{{ NODE_COUNT | default(DEFAULT_NODE_COUNT) }}"
    NODE_SIZE: "{{ NODE_SIZE | default(DEFAULT_NODE_SIZE) }}"
    SERVICE_ACCOUNT_NAME: "{{ SERVICE_ACCOUNT_NAME | default(DEFAULT_SERVICE_ACCOUNT_NAME) }}"

- name: Set gke cache
  set_fact:
    cacheable: yes
    SERVICE_ACCOUNT_KEY_PATH: "{{ WORK_DIR }}/{{ SERVICE_ACCOUNT_NAME }}-service-account-credentials.json"

- name: Set KUBECONFIG cache
  set_fact:
    FQ_CLUSTER_NAME: "{{ FQ_CLUSTER_NAME | default('gke_' + PROJECT_ID + '_' + CLUSTER_ZONE + '_' + CLUSTER_NAME) }}"
    CLUSTER_KUBECONFIG: "{{ CLUSTER_KUBECONFIG | default(WORK_DIR + '/' + CLUSTER_NAME + '-' + CLUSTER_ZONE + '.context.json') }}"

- name: Confirm WORK_DIR
  file: 
    path: "{{ WORK_DIR }}"
    state: directory  

- name: Set default project
  shell: gcloud config set project "{{ PROJECT_ID }}"

- name: Set compute/zone
  shell: gcloud config set compute/zone {{ CLUSTER_ZONE }}

- name: Create gcp cluster
  shell: |
    gcloud container clusters create {{ CLUSTER_NAME }} \
      --zone {{ CLUSTER_ZONE }} \
      --machine-type={{ NODE_SIZE }} \
      --num-nodes={{ NODE_COUNT }} \
      --enable-stackdriver-kubernetes \
      --subnetwork=default \
      --enable-ip-alias \
      --no-enable-autoupgrade \
      --no-enable-autorepair \
      --project {{ PROJECT_ID }}
  register: status 
  failed_when:  
    - status.rc == 1
    - "'Already exists' not in status.stderr"

- name: Obtain PROJECT_NUMBER
  shell: gcloud projects describe {{ PROJECT_ID }} --format="value(projectNumber)"
  register: project_number

- name: Create ASM service account
  ignore_errors: yes
  shell: gcloud iam service-accounts create {{ SERVICE_ACCOUNT_NAME }} --project={{ PROJECT_ID }}
  register: status
  failed_when:
    - status.rc == 1
    - "'already exists' not in status.stderr"

- name: Bind gkehub.connect IAM role to service account
  shell: |
    gcloud projects add-iam-policy-binding {{ PROJECT_ID }} \
     --member="serviceAccount:{{ SERVICE_ACCOUNT_NAME }}@{{ PROJECT_ID }}.iam.gserviceaccount.com" \
     --role="roles/gkehub.connect"

- name: Download service account credential file
  shell: |
    gcloud iam service-accounts keys create {{ SERVICE_ACCOUNT_KEY_PATH }} \
      --iam-account="{{ SERVICE_ACCOUNT_NAME }}@{{ PROJECT_ID }}.iam.gserviceaccount.com"
  args:
    creates: "{{ SERVICE_ACCOUNT_KEY_PATH }}"

- name: Register the cluster
  shell: |
    gcloud container hub memberships register {{ CLUSTER_NAME }} \
    --gke-cluster={{ CLUSTER_ZONE }}/{{ CLUSTER_NAME }} \
    --service-account-key-file={{ SERVICE_ACCOUNT_KEY_PATH }}
  register: status
  failed_when:
    - status.rc == 1
    - "'already exists' not in status.stderr"

- name: Set workload pool
  set_fact:
    cacheable: yes
    WORKLOAD_POOL: "{{ PROJECT_ID }}.svc.id.goog"
    MESH_ID: "proj-{{ PROJECT_NUMBER | default(project_number.stdout) }}"

- name: Set MESH_ID label
  shell: gcloud container clusters update {{ CLUSTER_NAME }} --update-labels=mesh_id={{ MESH_ID }}

- name: Enable workload identity
  shell: gcloud container clusters update {{ CLUSTER_NAME }} --workload-pool={{ WORKLOAD_POOL }}

- name: Enable Cloud Monitoring and Cloud Logging in GKE
  shell: gcloud container clusters update {{ CLUSTER_NAME }} --enable-stackdriver-kubernetes

- block:
  - name: Rename cluster
    shell: |
      kubectx {{ CLUSTER_NAME }}={{ FQ_CLUSTER_NAME }}
      kubectx {{ CLUSTER_NAME }}
  rescue:
    - name: RESCUE - Wait for the cluster...
      pause:
        seconds: 15

    - name: RESCUE - Rename cluster
      shell: |
        kubectx {{ CLUSTER_NAME }}={{ FQ_CLUSTER_NAME }}
        kubectx {{ CLUSTER_NAME }}

- name: Generate kubeconfig file    
  shell: kubectl config view --minify --flatten --context={{ CLUSTER_NAME }} 
  register: kubeconfig_content  

- name: Create kubeconfig file
  copy: 
    content: "{{ kubeconfig_content.stdout }}"
    dest: "{{ CLUSTER_KUBECONFIG }}"     

- name: Ensure you have cluster-admin on the cluster
  ignore_errors: yes
  shell: kubectl create clusterrolebinding user-cluster-admin --clusterrole cluster-admin --user {{ GCLOUD_ACCOUNT }}
  failed_when:  
    - status.rc == 1
    - "'already exists' not in status.stderr"
    
- name: Update authentication credentials
  shell: gcloud container clusters get-credentials {{ CLUSTER_NAME }} --zone {{ CLUSTER_ZONE }}
